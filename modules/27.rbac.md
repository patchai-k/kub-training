# Namespaces and RBAC

## Module Objectives

1. Create a Namespace
1. Add a user to the cluster
1. Create a Role, assign it to the user and make sure it is enforced
1. Create a ClusterRole, assign it to the user and make sure it is enforced

---

## Create a Namespace

Namespaces provide for a scope of Kubernetes objects. You can think of it as a workspace you are sharing with other users.

With namespaces one may have several virtual clusters backed by the same physical cluster. Names are unique within a Namespace, but not across Namespaces.

The cluster administrator can divide physical resources between Namespaces using quotas.

Namespaces cannot be nested.

Low-level infrastructure resources like Nodes and PersistentVolumes are not associated with a particular Namespace.

1. List all Namespaces in the system

    ```shell
    kubectl get ns
    ```

1. Use `describe` to learn more about a particular Namespace.

    ```shell
    kubectl describe ns default
    ```

1. Save the following file as `workshop-ns.yaml`.

    ```yaml
    apiVersion: v1
    kind: Namespace
    metadata:
      name: workshop
    ```

1. Apply the manifest to create a new Namespace called `workshop`.

    ```shell
    kubectl apply -f workshop-ns.yaml
    ```

1. List Namespaces again.

    > Note: You should see the Namespace `workshop` in the list.

## Add a User to the Cluster

Kubernetes has two types of users. The first is human users. They are managed outside the cluster in gSuite. The second type is service accounts. Service accounts are used by processes to access the Kubernetes API.

In this exercise you will create a service account and configure `gcloud` to use it.

>Note: Typically you login as a human user, not as a service account. You would normally create additional human users in gSuite. Unfortunately, adding human users is out of scope for this workshop.

1. Create a service account in the new workspace.

    ```shell
    kubectl create serviceaccount workshop-user --namespace workshop
    ```

1. Set up authentication for `kubectl` with the service account. You will use the context `gke-workshop` for normal operations and `limited` for operations as `workshop-user`.

    ```shell
    kubectl config set-credentials workshop-user --token=$(kubectl get secret $(kubectl get secret -n workshop | grep workshop-user-token | cut -f 1 -d " ") -n=workshop -o jsonpath={.data.token} | base64 --decode)
    ```

1. Make a backup copy of `~/.kube/config`.

    ```shell
    cp ~/.kube/config ~/.kube/config.ORIG
    ```

1. Create a new context using the new serviceaccount

   1. Rename the original context `gke-workshop`.

      ```shell
      CLUSTER_NAME=$(kubectl config view --minify -o jsonpath={.current-context})
      kubectl config rename-context $CLUSTER_NAME gke-workshop
      ```

   1. Create a new context named `limited` using the same cluster, but with the user `workshop-user` and the namespace `workshop`.

      ```shell
      kubectl config set-context limited --cluster $CLUSTER_NAME --user workshop-user --namespace workshop
      ```

   1. Set the current-context to `gke-workshop`.

      ```shell
      kubectl config use-context gke-workshop
      ```

   1. List the current contexts.  It should look similar to this:

      ```shell
      CURRENT   NAME           CLUSTER                       AUTHINFO                     NAMESPACE
      *         gke-workshop   gke_us-west1-c_k8s-training   gke_us-west1-c_k8s-training
                limited        gke_us-west1-c_k8s-training   workshop-user                workshop
      ```

       > Note: With each context you can set a default Namespace to use for all kubectl commands. This can be overwritten by specifying an explicit Namespace in the metadata of a manifest file.

1. Check if you can get Pods with the `gke-workshop` context.

    ```shell
    kubectl auth can-i get pods
    ```

    > Note: Output should be `yes`.

1. Switch between contexts.

    ```shell
    kubectl config use-context limited
    ```

1. Check if you can get Pods with the `limited` context.

    ```shell
    kubectl auth can-i get pods
    ```

    > Note: Output should be `no`. The user can do nothing as you didn't associate it with any role.

1. Switch back to the normal context.

    ```shell
    kubectl config use-context gke-workshop
    ```

## Create a Role, Assign it to the User and Make Sure it is Enforced

A Role is a set of rules that are applied to the Namespace. ClusterRole is applied to the whole cluster.

In both cases you describe the objects you want to grant access to and operations user may execute against these objects.

For the Role to take effect you must bind it to the user.

1. Create `worker-role.yaml` file which grants permissions to create Pods and Deployments.

    ```yaml
    kind: Role
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      namespace: workshop
      name: worker
    rules:
    - apiGroups: [""]
      resources: ["pods"]
      verbs: ["get", "watch", "list", "create"]
    - apiGroups: ["extensions", "apps"]
      resources: ["deployments"]
      verbs: ["get", "watch", "list", "create"]
    ```

    > Note: The `nginx` deployment created later might be of either `extensions` or `apps` API groups depending on your client version. For simplicity, we will use both in this workshop.

1. Apply the manifest.

    ```shell
    kubectl apply -f worker-role.yaml
    ```

1. Create a RoleBinding `worker-rolebinding.yaml` between user and the Role.

    ```yaml
    kind: RoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: worker
      namespace: workshop
    subjects:
    - kind: User
      name: system:serviceaccount:workshop:workshop-user
      apiGroup: rbac.authorization.k8s.io
    roleRef:
      kind: Role
      name: worker
      apiGroup: rbac.authorization.k8s.io
    ```

    > Note: This RoleBinding is for the `workshop` Namespace only.

1. Apply the manifest.

    ```shell
    kubectl apply -f worker-rolebinding.yaml
    ```

1. Switch context to `limited`.

    ```shell
    kubectl config use-context limited
    ```

1. Create an `nginx` Deployment.

    ```shell
    kubectl run nginx --image=nginx -n workshop
    ```

1. Check that the Deployment and Pod was created successfully.

    ```shell
    kubectl get pods -n workshop
    ```

    Sample output:
    ```
    NAME                     READY   STATUS    RESTARTS   AGE
    nginx-64f497f8fd-kqgzr   1/1     Running   0          18s
    ```


## Create a ClusterRole, Assign it to the User and Make Sure it is Enforced

1. While in the `limited` context, verify the limited user can't read nodes in the cluster.

    ```shell
    kubectl get nodes
    ```

1. Switch to the normal context.

    ```shell
    kubectl config use-context gke-workshop
    ```

1. Create the file `cr-node-reader.yaml` for creating a `ClusterRole` to list nodes.

    ```yaml
    kind: ClusterRole
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: node-reader
    rules:
    - apiGroups: [""]
      resources: ["nodes"]
      verbs: ["get", "watch", "list"]
    ```

    > Note: Nodes are cluster-wide resources and are not associated with a particular Namespace.

1. Apply the manifest.

    ```shell
    kubectl apply -f cr-node-reader.yaml
    ```

1. Bind the `node-reader` ClusterRole to the service account in the file `crb-node-reader.yaml`.

    ```yaml
    kind: ClusterRoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: read-nodes
    subjects:
    - kind: User
      name: system:serviceaccount:workshop:workshop-user
      apiGroup: rbac.authorization.k8s.io
    roleRef:
      kind: ClusterRole
      name: node-reader
      apiGroup: rbac.authorization.k8s.io
    ```

1. Apply the manifest.

    ```shell
    kubectl apply -f crb-node-reader.yaml
    ```

1. Now verify that user may list nodes.

    ```shell
    kubectl config use-context limited
    ```

    ```shell
    kubectl get nodes
    ```

    Sample output:
    ```
    NAME                                          STATUS   ROLES    AGE   VERSION
    gke-gke-workshop-default-pool-5d910404-t38p   Ready    <none>   3h    v1.13.11-gke.14
    ```

## Optional Exercise

1. Switch back to the unrestricted context and delete the `nginx` Deployment.

    ```shell
    kubectl delete deployment nginx
    ```

1. Edit the `worker-role.yaml` and delete the `pods` permissions. Reapply the worker role then try to deploy `nginx` again. What happens? Can you explain the outcomes?


> Note: Ensure you switch back to the gke-context when you have finished the exercises
